---
title: "STA610 Case Study 1"
author: 
  -  Emily Gentles (Presenter)   
  -  Weiyi Liu (Writer)   
  -  Jack McCarthy (Programmer)   
  -  Qinzhe Wang (Coordinator & Checker)   
  
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  pdf_document:
    latex_engine: xelatex
fontsize: 11pt
geometry: margin=1.5cm
---


```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message = FALSE, cache = TRUE)
library(tidyverse)
library(janitor)
library(gridExtra)
library(cowplot)
library(knitr)
require(magrittr)
require(dplyr)
library(kableExtra)
library(readr)
library(tidyr)
library(broom)
library(lme4)
library(glmmTMB)
library(sjPlot)
library(brms)
library(coda)
library(rstan)
library(tidybayes)
library(naniar)
library(olsrr)
library(lmerTest)
#library(rlist)
library(XML)
require(lattice)


# devtools::install_github("goodekat/redres")
library(redres)


```

```{r}
load('streetrx.RData')
```



# Introduction

Prescription opioid abuse plays an essential role in public health issues. The price of prescription opioids indicates the supply-demand relationship of drugs. This study case aims to explore the relationship between drugs’ unit price and other factors. More specifically, our group’s interest is to explore the factors related to the cost per milligram and the heterogeneity in the region. The dataset is provided by StreetRx, a reporting tool for people at large to anonymously report the price they paid or heard for diverted prescription drugs.

Our drug interest is Morphine. Morphine is used to “relieve moderate to severe pain and maybe habit-forming,” especially with prolonged use (MedlinePlus). 



# EDA

### Missing Values

```{r, fig.width=6, fig.height=3.5,results ='hide'}
na_check <- streetrx %>%
  filter(api_temp == 'morphine') %>%
  mutate_all( list( ~na_if(., '') ) ) %>%
  droplevels()

dim(na_check)
sum(is.na(na_check))

sum(is.na(na_check$Primary_Reason))

sum(is.na(na_check$source))

sum(is.na(na_check))

```

```{r,fig.width=6, fig.height=3.5}
gg_miss_upset(na_check)
```


```{r,results ='hide'}
# subset for group drug

morph_data <- streetrx %>%
  filter(api_temp == 'morphine')

morph_data$Primary_Reason <- droplevels(morph_data$Primary_Reason)
levels(morph_data$Primary_Reason)[1] <- "8 Prefer not to answer"
levels(morph_data$Primary_Reason)[2] <- "8 Prefer not to answer"

morph_data$source <- droplevels(morph_data$source)
levels(morph_data$source)[1] <- "Blank"

morph_data <- morph_data %>% 
  filter(between(ppm, 0.000001, 10)) %>%
  mutate_all( list( ~na_if(., '') ) ) %>%
  drop_na() %>%
  clean_names() %>%
  mutate(
    quarter=substring(yq_pdate, 5, 5),
    year=substring(yq_pdate, 1, 4),
    state=recode_factor(droplevels(state), 'USA'='Unknown')
  ) 


nrow(morph_data)

sum(morph_data$ppm <=0)
```


The dataset (Morphine) contains 9,268 observations with 13 variables. There are 13,443 empty cells (both the missing values and the blank). To maintain the statistical power and avoid bias, our group decided to recode the empty cells and "0 Reporter did not answer this question" in `Primary_Reason` (5061 in total)  as "8 Prefer not to answer" and recode the empty cells in `source` (3942 in total) as "Blank" because of the high missing rates. Then, we removed other rows with missing values.

In addition, we think there is no reason that the price per milligram can be a non-positive value or values greater than 10 (may because some people input the total price by mistake). The number of the observations we have is 5,582 now.


### Response Variable: Price per milligram 


```{r, fig.width=10, fig.height=3.5}
# remove extreme outliers based on quantiles

# untransformed density
p1 <- morph_data %>%
  ggplot(aes(x=ppm)) +
    geom_histogram(
      aes(y=..density..), 
      color='black', 
      linetype='dashed',
      size=0.5,
      fill='lightblue', 
      alpha=0.5,
      bins=20
    ) +
    geom_density(size=0.75, bw=0.3) +
    labs(title='Distribution of morphine ppm') +
    theme_bw()

# log-transformed density
p2 <- morph_data %>%
  ggplot(aes(x=log(ppm))) +
    geom_histogram(
      aes(y=..density..), 
      color='black', 
      linetype='dashed',
      size=0.5,
      fill='lightcoral', 
      alpha=0.5,
      bins=20
    ) +
    geom_density(size=0.75, bw=0.3) +
    labs(title='Distribution of morphine log(ppm)') +
    xlim(-7, 3) +
    theme_bw()

grid.arrange(p1, p2, ncol=2)


```


Whether we fit a hierarchical model or linear regression, the response variable should be normally distributed. From the histogram on the left, the distribution of `ppm` is clearly right-skewed. Since `ppm` is strictly non-negative, a log transformation may be appropriate. The distribution of 
`log(ppm)` is given above, and appears closer to the desired normal.



### Grouping Variable: city, state, and USA_region

Since we want to analyze the heterogeneity in pricing by location, we have three choices of grouping variable, `city`, `state`, and `USA_region`.

#### City

There are 1642 unique `city` values, and many cities have small sample size (i.e. less than 5 observations). We decide not o use `city` as the grouping variable (see appendix).


```{r}
length(unique(morph_data$city))
length(unique(morph_data$state))
length(unique(morph_data$usa_region))
```

```{r}
unique(morph_data$state)
```

#### State

As for state, we examined the sample sizes in each group and decide to out filter Puerto Rico and Vermont, because they have less than 5 observations. 

```{r}
state_size <- morph_data %>%
  group_by(state) %>%
  summarise(n = n(), .groups = "drop")  %>%
  arrange(n) %>%
  pivot_wider(
    names_from=state,
    values_from=n
  )

state_size %>% 
  dplyr::select(1:5) %>%
  kable(
    caption = '5 States with Smallest Sample Size',
    align='c', 
    booktabs=TRUE) %>%
  kable_styling(latex_options = c('hold_position'))

```


```{r}
# remove low sample size states
morph_data <- morph_data %>%
  mutate(state=as.character(state)) %>%
  filter(!state %in% c(
    'Puerto Rico', 'Vermont'
  ))
```


```{r, fig.width=10, fig.height=3}
morph_state <- morph_data %>%
  filter(state %in% state.name) %>%
  mutate(state_abv=state.abb[match(state,state.name)])


grand_mean <- mean(morph_state$ppm)

p3 <- morph_state %>%
  group_by(state_abv) %>%
  summarise(n = n(), mean = mean(ppm)) %>%
  ggplot(aes(x=n, y=mean)) +
    geom_hline(
      aes(yintercept=grand_mean),
      linetype='dashed',
      color='red',
      size=0.75
    ) +
    geom_point() +
    labs(x='sample size', y='mean log(ppm)') +
    theme_bw()


p4 <- morph_state %>%
  ggplot(aes(y=log(ppm), x=state_abv)) +
    geom_boxplot(
      fill=rainbow(49),
      alpha=0.5    
    ) +
    scale_x_discrete(guide=guide_axis(angle = 90)) +
    theme_bw() +
    labs(x='state')

cowplot::plot_grid(p3, p4, rel_widths = c(1, 2))
```

Then we inspect the state-level differences closer by plotting the group-level means agains the sample sizes. We observed that the within-state means for states with smaller sample sizes vary a lot, while the within-state means for states with higher sample sizes in general adhere more closely to the grand mean. This is conducive to the borrowing of information between states with a hierarchical model. 
From the above boxplot of `log(ppm)` against `state`, it is also evident that the `log(ppm)` distributions differ across states. This indicates the potential state-level differences in drug prices. Therefore, we decide to use state as our grouping variable at this stage.


#### Region

From the boxplot we still see the `log(ppm)` distributions differ slightly across regions, though not that much as across states. We may also consider using region as the grouping variable.

```{r, fig.height=3, fig.width=10}
t1 <- morph_state %>%
  group_by(usa_region) %>%
  summarise(n=n(), mean=round(mean(log(ppm)), 3)) %>%
  tableGrob()

p5 <- morph_state %>%
  ggplot(aes(y=log(ppm), x=usa_region)) +
    geom_boxplot() +
    stat_summary(
      fun.y=mean, 
      geom='point',
      color='red',
      size=3
    ) +
    theme_bw()

grid.arrange(t1, p5, ncol=2, widths=c(2, 2))
```


### Date (price_date)

As for the `price_date`, we noticed some observations are prior to the establishment of StreetRx, which might be wrong inputs. We dropped the observations prior to 2010. For the rest observations, we came up with two ways of data cleaning on the date variable. The first choice is to choose a starting date and convert the feature as the date differences (`date_diff`) from that starting date. The second choice is to split this date variable into two components, `year` and `quarter`, so that we can explore the trend of unit drug price over time and the seasonality. 

Our visualizations suggested there is no clear trend that the log value of per milligram price of morphine varies along with `date_diff`. However, for different `year` and `quarter`, the `log(ppm)` value varies a little bit (see appendix). 



```{r results='hide'}
min(as.Date(morph_data$price_date, "%m/%d/%y")) #2013-01-01
morph_data %>% group_by(year) %>% summarise(n = n())
```

```{r}
# remove data prior to 2010
morph_data <- morph_data %>%
  mutate(Year=as.character(year)) %>%
  filter(!year %in% c(
    1969, 2000, 2002, 2005
  ))
```


```{r}
# date_diff
morph_data <- morph_data %>% 
  mutate(date_diff = as.numeric(
    as.Date(morph_data$price_date, "%m/%d/%y") - as.Date("2010-01-01")
    )
  )
```


```{r}
morph_data %>%
  ggplot(aes(x=date_diff)) +
    geom_histogram(
      aes(y=..density..), 
      color='black', 
      linetype='dashed',
      size=0.5,
      fill='lightblue', 
      alpha=0.5,
      bins=30
    ) +
    geom_density(size=0.75, bw=100) +
    labs(title='Date Distribution') +
    theme_bw()
```

```{r}
morph_data %>%
  ggplot(aes(x=date_diff, y=log(ppm))) +
    geom_point() +
    geom_smooth() +
    theme_bw()

# check for random slopes
# morph_data_a <- subset(morph_data,state %in% c("Arizona", "Texas","California", "Pennsylvania"))
# morph_data_a %>% ggplot(aes(x = date_diff, y = log(ppm))) + 
#   geom_point() +
#   geom_smooth() +
#   theme_bw() +
#   facet_wrap('state', scales = "fixed")

```



```{r,fig.width=8, fig.height=3.5}
yearplot <- morph_data %>%
  ggplot(aes(x = year,y = log(ppm))) +
  geom_boxplot() +
  labs(x='Year') +
  stat_summary(
    fun.y=mean, 
    geom='point',
    color='red',
    size=3
  ) +
  theme_bw()


quarterplot <- morph_data %>%
  ggplot(aes(x = quarter,y = log(ppm))) +
  geom_boxplot() +
  labs(
    x='Quarter',
    y=''
  )  +
  stat_summary(
    fun.y=mean, 
    geom='point',
    color='red',
    size=3
  ) +
  theme_bw()

grid.arrange(yearplot, quarterplot, ncol=2)
```

### Bulk_purchase

There is no need to conduct any data cleaning on `bulk_purchase`. And from the boxplot (see appendix), there is a slight trend that the drug price may be lower if purchased in bulk. Therefore, `bulk_purchase` might be a potential predictor.

```{r, fig.width=6, fig.height=3.5}
morph_data %>%
  ggplot(aes(x = bulk_purchase,y = log(ppm))) +
  geom_boxplot() +
  labs(x='Bulk Purchase') +
  stat_summary(
    fun.y=mean, 
    geom='point',
    color='red',
    size=3
  ) +
  theme_bw()

```




### Source

We have recoded the missing value as "Blank" and the name of websites as "Internet". And we dropped the only observation whose `source` is "Drug Forum". From the boxplot, we see the `log(ppm)` value varies among different sources (see appendix).

```{r, fig.width=6, fig.height=3.5}
# unique(morph_data$source)

# combine internet levels into single level
morph_data <- morph_data %>%
  mutate(source=replace(
    source, !source %in% c(
      "Blank",
      'Personal',
      'Heard it', 
      'Internet', 
      'Internet Pharmacy', 
      'Drug forum'
    ), 'Internet'
  )) %>%
  droplevels()


morph_data <- morph_data %>%
  mutate(source=as.character(source)) %>%
  filter(source != "Drug forum")

morph_data %>%
  ggplot(aes(x = source,y = log(ppm))) +
  geom_boxplot() +
  stat_summary(
    fun.y=mean, 
    geom='point',
    color='red',
    size=2
  ) +
  theme_bw()


# morph_data %>%
#   group_by(source) %>%
#   summarize(n =n())
```


### Primary Reason

For `primary_reason`, we have converted the empty cells and "0 Reporter did not answer this question" to "8 Prefer not to answer". The `log(ppm)` value varies a lot among different reasons for purchasing the morphine (see appendix).

```{r, fig.width=6, fig.height=3.5}
morph_data %>%
  ggplot(aes(x = primary_reason,y =log(ppm))) +
  geom_boxplot() +
  coord_flip() +
  labs(x = "log(ppm)", y = "Reason")  +
    stat_summary(
      fun.y=mean, 
      geom='point',
      color='red',
      size=3
    ) +
  theme_bw()

```


### Dosage Strength (mgstr)

From the scatter plot of `log(ppm)` against `mgstr`, there is a slight trend that the larger the dosage strength, the smaller the per milligram price. We have also noticed that `mgstr` only takes 16 discrete values. Therefore, we consider to label it into 4 levels ("low", "medium", "medium high", and "high") based on the 0.25, 0.5, and 0.75 quantiles of `mgstr`.


```{r}
morph_data %>%
  ggplot(aes(x=mgstr, y=log(ppm))) +
    geom_point() +
    geom_smooth() +
    theme_bw()

# morph_data %>%
#   ggplot(aes(x=log(mgstr), y=log(ppm))) +
#     geom_point() +
#     geom_smooth() +
#     theme_bw()

morph_data %>%
  ggplot(aes(x=mgstr)) +
    geom_histogram(
      aes(y=..density..), 
      color='black', 
      linetype='dashed',
      size=0.5,
      fill='lightblue', 
      alpha=0.5,
      bins=10
    ) +
    geom_density(size=0.75, bw=7.5) +
    labs(title='mgstr Distribution') +
    theme_bw()
```


```{r}
# check for random slopes
morph_data %>% ggplot(aes(x = mgstr, y = log(ppm))) + 
  geom_point() +
  geom_smooth() +
  theme_bw() +
  facet_wrap('usa_region', scales = "fixed")
```


```{r}
morph_data %>% 
  group_by(mgstr) %>% 
  summarize(n = n()) %>%
  pivot_wider(
    names_from=mgstr,
    values_from=n
  ) %>%
  kable(
    caption='Sample Size for mgstr Levels',
    align='c', 
    booktabs=TRUE
  ) %>%
  kable_styling(latex_options = c('hold_position'))

# inspect mgstr value quantiles
quantile(morph_data$mgstr, c(0.25, 0.5, 0.75)) %>%
  data.frame() %>%
  rename('mgstr'='.') %>%
  kable()

## here we decide to re-code mgstr by quantile
morph_data <- morph_data %>%
  mutate(mgstr2 = case_when(
    mgstr <= 15              ~ "1 low",
    mgstr >15 & mgstr <= 30  ~ "2 medium",
    mgstr >30 & mgstr <= 60  ~ "3 medium high",
    mgstr > 60            ~ "4 high")
  )

morph_data %>%
  ggplot(aes(x=mgstr2 ,y=log(ppm))) +
  geom_boxplot() +
  labs(y="log(ppm)", x="Strength")  +
  stat_summary(
    fun.y=mean, 
    geom='point',
    color='red',
    size=3
  ) +
  theme_bw()

# jpeg("EDAplotStrength.jpg", width = 500, height = 300)
# dev.off()
```

From the boxplot, we see a more clear trend that the `log(ppm)` values decrease as the dosage strength increase.



# Model

### Model Selection

Our research question is to investigate factors related to the per milligram price of morphine and explore heterogeneity in pricing by location. As discussed in the EDA part, we do not have enough data to estimate the effects in city-level. Meanwhile, the drug prices do not seem to change significantly across regions. Thus, state is a more preferable choice of accounting for location. Since many states have relatively small sample sizes, a hierarchical model allows us to borrow information across states.

Comparing three full models with different grouping variables, the AIC and BIC score also suggest choosing `state` as the group-level variable.

```{r}
# group by city
mod_1 <- lmer(data=morph_data, log(ppm) ~ (1 |city), REML=F)

# group by state
mod_2 <- lmer(data=morph_data, log(ppm) ~ (1 |state), REML=F)

# group by region
mod_3 <- lmer(data=morph_data, log(ppm) ~ (1 |usa_region), REML=F)

aic_score <- sapply(c(mod_1, mod_2, mod_3), AIC)
bic_score <- sapply(c(mod_1, mod_2, mod_3), BIC)

data.frame('Grouping' = c('City', 'State', 'Region'), 'AIC' = aic_score, 'BIC' = bic_score) %>%
  kable()
 
```


```{r}
# appendix
# group by city
mod_full_1 <- lmer(data=morph_data, log(ppm) ~ (1 |city) + date_diff + quarter + year + mgstr2 +
                bulk_purchase + primary_reason + source, REML=F)

# group by state
mod_full_2 <- lmer(data=morph_data, log(ppm) ~ (1 |state) + date_diff + quarter + year + mgstr2 +
                bulk_purchase + primary_reason + source, REML=F)

# group by region
mod_full_3 <- lmer(data=morph_data, log(ppm) ~ (1 |usa_region) + date_diff + quarter + year + mgstr2 +
                bulk_purchase + primary_reason + source, REML=F)

aic_score <- sapply(c(mod_full_1, mod_full_2, mod_full_3), AIC)
bic_score <- sapply(c(mod_full_1, mod_full_2, mod_full_3), BIC)

data.frame('Grouping' = c('City', 'State', 'Region'), 'AIC' = aic_score, 'BIC' = bic_score) %>%
  kable()
 
```

Our baseline model incorporates only the state-level random intercepts. For other individual level predictors, we add one variable to the model each time, and use both the Likelihood Ratio test and the BIC score to determine whether it should be added. The **LRT** is designed for nested models. While the BIC score considers both the likelihood and the model complexity, and gives a more general sense of model performance. The table below displays the results of model selection.

Our final model incorporates the grouping variable `state` and the individual level predictors `mgstr` (recoded as 4 levels), `bulk_purchase`, `quarter`, `source`. We also tried to using the full model as a starting point, and did stepwise backward elimination. The results agrees with our final model (See appendix).


bic <- up xiao  +




```{r}
modela <- lmer(log(ppm) ~  (1|state), data = morph_data, REML=F) # 
summary(modela)
```

```{r a}
modela <- lmer(log(ppm) ~  (1|state), data = morph_data, REML=F) # 


modelb <- lmer(log(ppm) ~  mgstr2 + (1|state), data = morph_data, REML=F) # 




# ===== 
modelc <- lmer(log(ppm) ~  mgstr2 + bulk_purchase + (1|state), data = morph_data, REML=F) # 

anova(modelb,modelc)


# ===== 

modeld <- lmer(log(ppm) ~  year + mgstr2 + bulk_purchase + (1|state), data = morph_data, REML=F)

modele <- lmer(log(ppm) ~  quarter + mgstr2 + bulk_purchase + (1|state), data = morph_data, REML=F) # 

modelf <- lmer(log(ppm) ~ date_diff + mgstr2 + bulk_purchase + (1|state), data = morph_data, REML=F) 

anova(modelc,modeld)

anova(modelc,modele) 

anova(modelc,modelf) 


# ===== 
modelg <- lmer(log(ppm) ~  quarter + source + mgstr2 + bulk_purchase + (1|state), data = morph_data, REML=F) # 

anova(modele,modelg) 

# ===== 

# Maybe a little cleaner way to do this
modelh<- lmer(log(ppm) ~  quarter + primary_reason + mgstr2 + bulk_purchase + (1|state), data = morph_data, REML=F) 

anova(modelg, modelh)

modelAll <- lmer(log(ppm) ~ quarter + primary_reason + mgstr2 + bulk_purchase + year + date_diff + source + (1|state), data = morph_data, REML=F)
step(modelAll)

```

```{r}
model <- c("log(ppm) ~  (1|state)",
           "log(ppm) ~  (1|state) + mgstr2",
           "log(ppm) ~  (1|state) + mgstr2 + bulk_purchase",
           "log(ppm) ~  (1|state) + mgstr2 + bulk_purchase + year",
           "log(ppm) ~  (1|state) + mgstr2 + bulk_purchase + quarter",
           "log(ppm) ~  (1|state) + mgstr2 + bulk_purchase + date_diff",
           "log(ppm) ~  (1|state) + mgstr2 + bulk_purchase + quarter + source",
           "log(ppm) ~  (1|state) + mgstr2 + bulk_purchase + quarter + source + primary_reason")
LRT <- c("",
         anova(modela,modelb)$`Pr(>Chisq)`[2],
         anova(modelb,modelc)$`Pr(>Chisq)`[2],
         anova(modelc,modeld)$`Pr(>Chisq)`[2],
         anova(modelc,modele)$`Pr(>Chisq)`[2],
         anova(modelc,modelf)$`Pr(>Chisq)`[2],
         anova(modele,modelg)$`Pr(>Chisq)`[2],
         anova(modelg,modelh)$`Pr(>Chisq)`[2])
BIC_score1 <- sapply(c(modela, modelb, modelc, modeld, modele, modelf, modelg, modelh), BIC)
data.frame("Model" = model, 'LRT p-value' = LRT, 'BIC' = BIC_score1) %>%
  kable()
```




```{r}
modelg <- lmer(log(ppm) ~  quarter + source + mgstr2 + bulk_purchase + (1|state), data = morph_data, REML=F)


modelgg <- lmer(log(ppm) ~  quarter + source + mgstr2 + bulk_purchase + (1|state) + 
                 quarter * bulk_purchase, data = morph_data, REML=F)

anova(modelg,modelgg)

modelggg <- lmer(log(ppm) ~  quarter + source + mgstr2 + bulk_purchase + (1|state) + 
                 quarter * mgstr2, data = morph_data, REML=F)

anova(modelg,modelggg)

modelgggg <- lmer(log(ppm) ~  quarter + source + mgstr2 + bulk_purchase + (1|state) + 
                 bulk_purchase * mgstr2, data = morph_data, REML=F)

anova(modelg,modelgggg)

modelggggg <- lmer(log(ppm) ~  quarter + source + mgstr2 + bulk_purchase + (1|state) + 
                 quarter * source, data = morph_data , REML=F)

anova(modelg,modelggggg)

modelgggggg <- lmer(log(ppm) ~  quarter + source + mgstr2 + bulk_purchase + (1|state) + 
                 bulk_purchase * source, data = morph_data, REML=F)

anova(modelg,modelgggggg)


modelggggggg <- lmer(log(ppm) ~  quarter + source + mgstr2 + bulk_purchase + (1|state) + 
                 source * mgstr2, data = morph_data, REML=F)

anova(modelg,modelggggggg)

```



```{r}
modelg <- lmer(log(ppm) ~  quarter + source + mgstr2 + bulk_purchase + (1|state), data = morph_data, REML=F)

```


### final model

Our final model is 
$$log(y_{ij}) = \beta_0 + b_{0j} + \beta_1 M_{ij} + \beta_2 B_{ij} + \beta_3 Q_{ij} + \beta_4 S_{ij} + \epsilon_{ij}$$
$$b_{0j} \sim \mathcal{N}(0, \tau^2) \perp \epsilon_{ij} \stackrel{iid} \sim \mathcal{N}(0, \sigma^2)$$
The response variable and predictors are defined as:

 - $y_ij$: Per miligram price of morphine for individual i in state j
 
 - $M_{ij}$: Dosage strength in mg of the units purchased, labeled into 4 levels
 
 - $B_{ij}$: Bulk purchase, an indicator for whether 10+ units were purchased at once
 
 - $Q_{ij}$: Quarter of the reported purchase
 
 - $S_{ij}$: Source of information (report purchases they did not personally make)

```{r}
# view coefficient estimates
view_coef <- function(model) {
  summary(model)$coefficients %>%
    as.data.frame() %>%
    mutate(`exp(Estimate)`=exp(Estimate)) %>%
    relocate(`exp(Estimate)`, .after=Estimate) %>%
    kable() %>%
    kable_classic(full_width=FALSE)
}



# view parameter estimates
view_params <- function(model) {
  params <- summary(model)$varcor %>%
    as.data.frame() %>%
    dplyr::select(vcov)
  
  rownames(params) <- c('$\\tau^2$', '$\\sigma^2$')
  colnames(params) <- c('Estimate')
  kable(params) %>% 
    kable_classic(full_width=FALSE)
}



```

```{r, fig.width=10, fig.height=10}
plot_qq <- function(model) {
  df <- data.frame(
    res=residuals(model, scaled=TRUE)
  )
  
  p <- ggplot(df, aes(sample=res)) + 
    stat_qq() + 
    stat_qq_line(
      linetype='dashed',
      color='red',
      size=1
    ) +
    labs(
      title='Normal QQ for Residuals',
      x='Theoretical Quantiles',
      y='Standardized Residuals'
    ) + theme_bw()
  
  return(p)
}
plot_ranef_qq <- function(model) {
  df <- data.frame(
    res=ranef(model)[[1]][[1]]
  )
  
  p <- ggplot(df, aes(sample=res)) + 
    stat_qq() + 
    stat_qq_line(
      linetype='dashed',
      color='red',
      size=1
    ) +
    labs(
      title='Normal QQ for Random Effects',
      x='Theoretical Quantiles',
      y='State Intercept'
    ) + theme_bw()
  
  return(p)
}
plot_res_fit <- function(model) {
  df <- data.frame(
    res=residuals(model),
    fit=fitted(model)
  )
  
  p <- ggplot(df, aes(x=fit, y=res)) +
    geom_point() +
    geom_hline(
      yintercept=0,
      linetype="dashed"
    ) +
    geom_smooth() +
    labs(
      title='Residuals vs. Fitted',
      x='Fitted',
      y='Residuals'
    ) + theme_bw()
  
  return(p)
}
plot_scale_loc <- function(model) {
  df <- data.frame(
    res=sqrt(residuals(model, scaled=TRUE)),
    fit=fitted(model)
  )
  
  p <- ggplot(df, aes(x=fit, y=res)) +
    geom_point() +
    geom_smooth() +
    labs(
      title='Scale-Location',
      x='Fitted',
      y=expression(sqrt('Standardized Residuals'))
    ) + theme_bw()
  
  return(p)
}
plot_res_dens <- function(model) {
  df <- data.frame(
    res=residuals(model)
  )
  
  p <- ggplot(df, aes(x=res)) +
    geom_density() +
    labs(
      title='Residuals Density',
      x='Residuals',
      y='Density'
    ) + theme_bw()
  
  return(p)
}
  
model_diag <- function(model) {
  p1 <- plot_res_fit(model)
  p2 <- plot_qq(model)
  p3 <- plot_ranef_qq(model)
  p4 <- plot_res_dens(model)
  
  cowplot::plot_grid(p1, p2, p3, p4, nrow=2)
}
```

```{r, fig.heigh=10, fig.width=10}
view_coef(modelg)
view_params(modelg)
model_diag(modelg)
```



Remove the data point with the lowest residual.

```{r, fig.heigh=10, fig.width=10}
# remove lowest residual data point
morph_data2 <- morph_data[-which.min(resid(modelg)),]


model_g2 <- lmer(log(ppm) ~  quarter + source + mgstr2 + bulk_purchase + (1|state), data = morph_data2, REML=F)


view_coef(model_g2)
view_params(model_g2)
model_diag(model_g2)
```


# Influence

```{r}
model_g2_inf<- influence(model_g2, group = "state")
```

```{r}
cooks_distance <- cooks.distance(model_g2_inf)
cutline <- 4 / length(unique(morph_data2$state))
infindiv <- cooks_distance > cutline

ggplot(data=NULL, aes(x=1:length(unique(morph_data2$state)), y=cooks_distance)) +
  geom_point() +
  geom_hline(
    yintercept=cutline,
    linetype='dashed',
    color='red',
    size=0.75
  ) +
  labs(
    x='Index',
    y='Cooks Distance'
  ) +
  theme_bw()

# jpeg("CooksDistance.jpg", width = 600)
# dev.off()

data.frame(
  cooks_distance,
  infindiv
) %>% 
  filter(infindiv == TRUE) %>%
  dplyr::select(2) %>%
  rename(`Cook's Distance`=1) %>%
  kable() %>%
  kable_classic(full_width=FALSE)
```

```{r, fig.heigh=10, fig.width=10}
# remove two most influential states
morph_data3 <- morph_data2 %>%
  filter(!state %in% c('Florida', 'California','Pennsylvania'))


model_g3 <- lmer(log(ppm) ~  quarter + source + mgstr2 + bulk_purchase + (1|state), data = morph_data3, REML=F)

view_coef(model_g3)
view_params(model_g3)
model_diag(model_g3)
```

Does not change much, but the sample size decreases sharply -> decide not to remove these groups.




```{r}
# view intercept estimates and intervals
dotplot(ranef(model_g2, condVar = TRUE))
ranef(model_g2, condVar = TRUE) %>% kable()
```






