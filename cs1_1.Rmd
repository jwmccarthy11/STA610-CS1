---
title: "STA610 Case Study 1"
author: "Emily Gentles, Weiyi Liu, Jack McCarthy, Qinzhe Wang"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: pdf_document
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message = FALSE, cache = TRUE)
library(tidyverse)
library(janitor)
library(gridExtra)
library(cowplot)
library(knitr)
require(magrittr)
require(dplyr)
library(kableExtra)
library(readr)
library(tidyr)
library(broom)
library(lme4)
library(glmmTMB)
library(sjPlot)
library(brms)
library(coda)
library(rstan)
library(tidybayes)
library(naniar)
library(olsrr)
library(lmerTest)
require(lattice)


# devtools::install_github("goodekat/redres")
#library(redres)


```

```{r}
load('streetrx.RData')
```

Qinzhe - Coordinator & Checker: Double-checks the work for reproducibility and errors. Also responsible for submitting the report and presentation files.
         Coordinator: Keeps everyone on task and makes sure everyone is involved. Also responsible for coordinating team meetings and defining the objectives for each meeting.

Emily - Presenter: Primarily responsible for organizing and putting the team presentations together.

Jack - Programmer: Primarily responsible for all things coding. The programmer is responsible for putting everyone’s code together and making sure the final product is “readable”.

Weiyi - Writer: Primarily responsible for putting together the final report.

# Introduction


# EDA


### Missing Values

```{r, fig.width=6, fig.height=3.5}
morph_data_na_checking <- streetrx[streetrx$api_temp == "morphine",]

morph_data_na_checking[morph_data_na_checking == ""] <- NA

morph_data_na_checking <- droplevels(morph_data_na_checking)
  
gg_miss_upset(morph_data_na_checking)
```

```{r}
# subset for group drug
streetrx[streetrx == ""] <- NA
morph_data <- streetrx %>%
  drop_na() %>%
  clean_names() %>%
  filter(api_temp == 'morphine') %>%
  mutate(
    quarter=substring(yq_pdate, 5, 5),
    year=substring(yq_pdate, 1, 4)
  )
```


```{r}
# replace state "USA" with "Unknown"
morph_data$state <- recode_factor(droplevels(morph_data$state), "USA" = "Unknown")

```


### Response Distribution

First, a look at the distributions of the response variable "ppm". Observations 
with ppm between the 0.1 and 99.9 percentiles were considered so as to avoid 
the influence of extreme outliers on the analysis of the ppm distribution.

```{r, fig.width=10, fig.height=3.5}
morph_trunc <- morph_data %>%
  filter(between(ppm, quantile(ppm, 0.001), quantile(ppm, 0.999)))

p1 <- morph_trunc %>%
  ggplot(aes(x=ppm)) +
    geom_histogram(
      aes(y=..density..), 
      color='black', 
      linetype='dashed',
      size=0.5,
      fill='lightblue', 
      alpha=0.5,
      bins=20
    ) +
    geom_density(size=0.75, bw=0.3) +
    labs(title='Distribution of morphine ppm') +
    theme_bw()

p2 <- morph_trunc %>%
  ggplot(aes(x=log(ppm))) +
    geom_histogram(
      aes(y=..density..), 
      color='black', 
      linetype='dashed',
      size=0.5,
      fill='lightcoral', 
      alpha=0.5,
      bins=20
    ) +
    geom_density(size=0.75, bw=0.3) +
    labs(title='Distribution of morphine log(ppm)') +
    xlim(-7, 3) +
    theme_bw()

grid.arrange(p1, p2, ncol=2)
```

The distribution of ppm is clearly right-skewed, and it is strictly nonnegative 
in value, so a log transformation may be appropriate. The distribution of 
log(ppm) is given above, and appears closer to the desired normal.

### state vs. log(ppm)

We see that there are 4 states that have a sample size of 1, North Dakota, Vermont, Washington DC, and Wyoming, as well as 1 state that has a sample size of 2, Alaska. Due to the extremely small sample sizes we decided to remove these states form our dataset to avoid computational instability.

```{r}
state_size <- morph_data %>%
  group_by(state) %>%
  summarise(n = n(), .groups = "drop")  %>%
  arrange(n) %>%
  pivot_wider(names_from = state,
            values_from = n)

# dim(state_size)[2]
small_sample <- state_size %>% 
  dplyr::select(1:7) %>%
  kable(caption = "7 states with smallest sample size ",
        align = "c", booktabs = TRUE) %>%
  kable_styling(latex_options = c("hold_position"))

large_sample <- state_size %>% 
  dplyr::select(44:50) %>%
  kable(caption = "7 states with largest sample size ",
        align = "c", booktabs = TRUE) %>%
  kable_styling(latex_options = c("hold_position"))

small_sample
large_sample

morph_data$state <- as.character(morph_data$state)

# remove states that have small sample size
morph_data <- morph_data %>%
  filter(state != "North Dakota") %>%
  filter(state != "Washington, DC") %>%
  filter( state != "Vermont") %>%
  filter(state != "Wyoming") %>%
  filter(state != "Alaska")

```


```{r, fig.width=10, fig.height=3}
morph_state <- morph_trunc %>%
  filter(state %in% state.name) %>%
  mutate(state_abv=state.abb[match(state,state.name)])

grand_mean <- mean(morph_state$ppm)

p3 <- morph_state %>%
  group_by(state_abv) %>%
  summarise(n = n(), mean = mean(ppm)) %>%
  ggplot(aes(x=n, y=mean)) +
    geom_hline(
      aes(yintercept=grand_mean),
      linetype='dashed',
      color='red',
      size=0.75
    ) +
    geom_point() +
    labs(x='sample size', y='mean log(ppm)') +
    theme_bw()

p4 <- morph_state %>%
  ggplot(aes(y=log(ppm), x=state_abv)) +
    geom_boxplot(
      fill=rainbow(49),
      alpha=0.5    
    ) +
    scale_x_discrete(guide=guide_axis(angle = 90)) +
    theme_bw() +
    labs(x='state')

cowplot::plot_grid(p3, p4, rel_widths = c(1, 2))
```

We observe that the within-state means for states with higher sample sizes in 
general adhere more closely to the grand mean. It is also evident that the log(ppm) 
distributions differ little as compared to the within-state variance. This is 
conducive to the borrowing of information between states.


### region vs. log(ppm)

We also have access to the broader region in which a purchase is made. This 
could be useful if we wanted to develop a simpler model that still captured 
variation by purchase location.

```{r, fig.height=3, fig.width=10}
t1 <- morph_state %>%
  group_by(usa_region) %>%
  summarise(n=n(), mean=round(mean(log(ppm)), 3)) %>%
  tableGrob()

p5 <- morph_state %>%
  ggplot(aes(y=log(ppm), x=usa_region)) +
    geom_boxplot() +
    stat_summary(
      fun.y=mean, 
      geom='point',
      color='red',
      size=3
    ) +
    theme_bw()

grid.arrange(t1, p5, ncol=2, widths=c(2, 2))
```


### source vs. log(ppm)

```{r, fig.width=6, fig.height=3.5}
# unique(morph_data$source)

source_index <- morph_data$source %in% c("Personal",
                                         "Heard it", 
                                         "Internet", 
                                         "Internet Pharmacy", 
                                         "Drug forum", NA)

morph_data$source[!source_index] <- "Internet"

morph_data <- droplevels(morph_data)
```

```{r, fig.height=3, fig.width=10}
t2 <- morph_data %>%
  group_by(source) %>%
  summarise(n=n(), mean=round(mean(log(ppm)), 3)) %>%
  tableGrob()

p6 <- morph_data %>%
  ggplot(aes(x = source,y = log(ppm))) +
  geom_boxplot()

grid.arrange(t2, p6, ncol=2, widths=c(2, 2))
```


### date

record `price_date` as a continuous variable counting days from some start date.

```{r}
#min(as.Date(morph_data$price_date, "%m/%d/%y")) #2013-01-01
morph_data <- 
  morph_data %>% 
  mutate(date_diff = as.numeric(as.Date(morph_data$price_date, "%m/%d/%y") - as.Date("2013-01-01")))
```

```{r}
date_hist <- morph_data %>%
  ggplot(aes(x = date_diff)) +
  geom_histogram()
date_hist
```



### year & quarter vs.log(ppm)

```{r,fig.width=10, fig.height=3.5}
t_year <- morph_data %>% group_by(year) %>% summarize(n = n()) %>% tableGrob()

yearplot <- morph_data %>%
  ggplot(aes(x = year,y = log(ppm))) +
  geom_boxplot()

t_quarter <- morph_data %>% group_by(quarter) %>% summarize(n = n()) %>% tableGrob()

quarterplot <- morph_data %>%
  ggplot(aes(x = quarter,y = log(ppm))) +
  geom_boxplot()

grid.arrange(t_year, yearplot, t_quarter, quarterplot, ncol=2, nrow = 2)
```

### bulk_purchase vs.log(ppm)

```{r, fig.width=6, fig.height=3.5}
morph_data %>%
  ggplot(aes(x = bulk_purchase,y = log(ppm))) +
  geom_boxplot()
```


### Primary_Reason vs.log(ppm)


```{r, fig.width=6, fig.height=3.5}
jpeg("EDAplotReason.jpg", width = 500)

morph_data %>%
  ggplot(aes(x = primary_reason,y =log(ppm))) +
  geom_boxplot() +
  coord_flip() +
  labs(x = "log(ppm)", y = "Reason")

dev.off()
```


### mgstr vs. log(ppm)

```{r}
plot(morph_data$mgstr, log(morph_data$ppm))
hist(morph_data$mgstr)

morph_data %>% group_by(mgstr) %>% summarize(n = n())
quantile(morph_data$mgstr)

## here we decide to re-code mgstr by quantile
morph_data <- morph_data %>%
  mutate(mgstr2 = case_when(mgstr <= 15 ~ "low",
                              mgstr >15 & mgstr <= 30  ~ "medium",
                              mgstr >30 & mgstr <= 50  ~ "medium high",
                              mgstr >=50 ~ "high"))

jpeg("EDAplotStrength.jpg", width = 500, height = 300)

morph_data %>%
  ggplot(aes(x = mgstr2,y =log(ppm))) +
  geom_boxplot() +
  coord_flip() +
  labs(x = "log(ppm)", y = "Strength")

dev.off()
```





# Model

```{r}
modela <- lmer(log(ppm) ~ date_diff + quarter + mgstr + bulk_purchase + primary_reason + source + (1|state), data = morph_data)
modelb <- lmer(log(ppm) ~ date_diff + quarter + mgstr + bulk_purchase + primary_reason + (1|state), data = morph_data)
modelc <- lmer(log(ppm) ~ date_diff + quarter + mgstr + bulk_purchase + (1|state), data = morph_data)
modeld <- lmer(log(ppm) ~ date_diff + quarter + mgstr + (1|state), data = morph_data)
modele <- lmer(log(ppm) ~ date_diff + quarter + (1|state), data = morph_data)
modelf <- lmer(log(ppm) ~ date_diff + (1|state), data = morph_data)

#m <- ols_step_best_subset(model)
#plot(m)
#selectedMod <- step(model)
#summary(selectedMod)

BIC_score <- sapply(c(modela, modelb, modelc, modeld, modele, modelf), BIC)
re_results <- data.frame('Grouping' = c('All', '- Source', '- Reason', '- Bulk', '- mgstr', '- quarter'), 'BIC' = BIC_score)
kable(re_results)
```
From this it looks like the best model includes date_diff, quarter, and mgstr 



### choose grouping variable

```{r}

morph_data <- morph_data %>% 
  filter(year != "2013" & year != "2014")

attach(morph_data)
quantile(mgstr)

morph_data <- morph_data %>%
  mutate(mgstr2 = case_when(mgstr >= 10 & mgstr < 15 ~ "low",
                              mgstr >= 15 & mgstr < 30 ~ "medium",
                              mgstr >= 30 & mgstr < 50 ~ "medium high",
                              mgstr >= 50  ~ "high"))



```


```{r}
mod_1 <- lmer(data=morph_data, log(ppm) ~ (1 |state) + date_diff + quarter + mgstr +
                bulk_purchase + primary_reason + source, REML=F)
mod_2 <- lmer(data=morph_data, log(ppm) ~ (1 |city) + date_diff + quarter + mgstr +
                bulk_purchase + primary_reason + source, REML=F)
mod_3 <- lmer(data=morph_data, log(ppm) ~ (1 |usa_region) + date_diff + quarter + mgstr +
                bulk_purchase + primary_reason + source, REML=F)


BIC_score <- sapply(c(mod_1, mod_2, mod_3), BIC)
re_results <- data.frame('Grouping' = c('State', 'City', 'Region'), 'BIC' = BIC_score)

jpeg("BICgroup.jpg", width = 350)

kable(re_results)

dev.off()

```

Choose `State` as our grouping variable


```{r}
mod_1 <- lmer(data=morph_data, log(ppm) ~ (1 |state) + date_diff + quarter + mgstr +
                bulk_purchase + primary_reason + source, REML=F)

mod_4 <- lmer(data=morph_data, log(ppm) ~ (1 |state) + date_diff + quarter + mgstr2 +
                bulk_purchase + primary_reason + source, REML=F)


mod_5 <- lmer(data=morph_data, log(ppm) ~ (1 |state) +  mgstr, REML=F)

mod_6 <- lmer(data=morph_data, log(ppm) ~ (1 |state) +  mgstr2, REML=F)


sapply(c(mod_1, mod_4,mod_5,mod_6), BIC)

step(mod_4)
```



```{r}
# Test date_num
mod_drop_date <- lmer(data=morph_data, log(ppm) ~ (1 |state)  + quarter + mgstr2 +
                bulk_purchase + primary_reason + source, REML=F)


mod_drop_quater <- lmer(data=morph_data, log(ppm) ~ (1 |state) + date_diff  + mgstr2 +
                bulk_purchase + primary_reason + source, REML=F)

mod_drop_bulk_purchase <- lmer(data=morph_data, log(ppm) ~ (1 |state) + date_diff + quarter + mgstr2 
                               + primary_reason + source, REML=F)

mod_drop_primary_reason <- lmer(data=morph_data, log(ppm) ~ (1 |state) + date_diff + quarter + mgstr2 +
                bulk_purchase+ source, REML=F)

mod_drop_mgstr <- lmer(data=morph_data, log(ppm) ~ (1 |state) + date_diff + quarter  +
                bulk_purchase + primary_reason + source, REML=F)


mod_drop_source <- lmer(data=morph_data, log(ppm) ~ (1 |state) + date_diff + quarter + mgstr2 +
                bulk_purchase + primary_reason, REML=F)


anova(mod_4,mod_drop_date)$`Pr(>Chisq)`[2] 
anova(mod_4,mod_drop_quater)$`Pr(>Chisq)`[2] # add
anova(mod_4,mod_drop_bulk_purchase)$`Pr(>Chisq)`[2] # add
anova(mod_4,mod_drop_primary_reason)$`Pr(>Chisq)`[2] # add
anova(mod_4,mod_drop_mgstr)$`Pr(>Chisq)`[2] # add
anova(mod_4,mod_drop_source)$`Pr(>Chisq)`[2] 
```


We now have `quarter`, `bulk_purchase`, `primary_reason` and `mgstr2` in our model, regarding `state` as the grouping variable.

Why/how did we choose the variables to put into the model? too many predictors?

Unique values: 
state = 45
quarter = 4
bulk purchase = 2
primary reason = 10
mgstr = 14

only have 1831 observations

### final model


```{r, eval =T}
mod_final1 <- lmer(data=morph_data, log(ppm) ~ (1 |state)  + mgstr + quarter +
                bulk_purchase + primary_reason, REML=F)

mod_final2<- lmer(data=morph_data, log(ppm) ~ (1 |state)  + mgstr2 + quarter +
                bulk_purchase + primary_reason, REML=F)

BIC(mod_final1)
BIC(mod_final2)
```

```{r}
tab_model(mod_final2)

webshot::webshot("summary.html", "summary.png")
```


```{r error=FALSE, fig.align='center', fig.height=, message=FALSE, warning=FALSE, fig.height=2}
resqq <- plot_resqq(mod_final2)
ranefci <- plot_ranef(mod_final2)
grid.arrange(resqq, ranefci, ncol = 2)
```



Remove the data point with the lowest residual.

```{r}
morph_data2 <- morph_data[-which.min(resid(mod_final2)),]

mod_final3 <- lmer(data=morph_data2, log(ppm) ~ (1 |state)  + mgstr2 + 
                     bulk_purchase + quarter + 
                primary_reason , REML=F)


resqq <- plot_resqq(mod_final3)
ranefci <- plot_ranef(mod_final3)
grid.arrange(resqq, ranefci, ncol = 2)

```


# Influence

```{r}
mod_final3_inf<- influence(mod_final3, group = "state")
```

```{r}
cooks_distance <- cooks.distance(mod_final3_inf)


cutline <- 4/length(unique(morph_data2$state))


infindiv <- cooks_distance > 4/length(unique(morph_data2$state))

jpeg("CooksDistance.jpg", width = 600)

plot(cooks_distance) + abline(h = cutline, col = "red")

dev.off()

subset(data.frame(rownames(mod_final3_inf$`fixed.effects[-state]`),cooks_distance,infindiv),infindiv == TRUE)

```


```{r}
morph_data3  <- morph_data2 %>%
  filter(state != "California") %>%
  filter(state != "Arizona") 


mod_final4 <- lmer(data=morph_data3, log(ppm) ~ (1 |state)  + mgstr2 + 
                     bulk_purchase + quarter + 
                primary_reason , REML=F)


resqq <- plot_resqq(mod_final4)
ranefci <- plot_ranef(mod_final4)
grid.arrange(resqq, ranefci, ncol = 2)
```

```{r}

jpeg("randomef.png", width = 350)

dotplot(ranef(mod_final2, condVar = TRUE))

dev.off()
```


Plots are not good -> not remove those two states?





Interclass correlation is 0.0159, very small so very little correlation across states.
Including bulk purchases, the interclass correlation is 0.016, so bulk purchase actually increases the heterogeneity across states by a very small amount.

Make table with results for all models tested in ANOVA




